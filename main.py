"""
Project: Tactix
File Created: 2026-02-02 11:55:51
Author: Xingnan Zhu
File Name: main.py
Description: xxx...
"""


"""
Project: Tactix
File Name: main.py
"""

import cv2
import numpy as np
import supervision as sv
from tqdm import tqdm

# === æ ¸å¿ƒæ¨¡å—å¼•å…¥ ===
from tactix.vision.detector import Detector
from tactix.vision.tracker import Tracker
from tactix.vision.camera import CameraTracker
from tactix.vision.transformer import ViewTransformer
from tactix.semantics.team import TeamClassifier
from tactix.tactics.pass_network import PassNetwork
from tactix.visualization.minimap import MinimapRenderer
from tactix.core.keypoints import get_target_points
from tactix.core.types import TeamID, Point

def main():
    # ==========================================
    # 1. é…ç½® (Config)
    # ==========================================
    MODEL_PATH = "assets/weights/football_v1.pt" 
    SOURCE_VIDEO_PATH = "assets/samples/InterGoalClip.mp4"
    TARGET_VIDEO_PATH = "assets/output/Final_Result.mp4"
    PITCH_IMAGE_PATH = "assets/pitch_bg.png"

    # æ ¡å‡†æ•°æ® (ç¬¬0å¸§)
    CALIBRATION_SOURCE = np.array([(137, 89), (1126, 87), (1045, 398), (138, 222)])
    CALIBRATION_TARGETS = ['L_PA_TOP_LINE', 'MID_TOP', 'CIRCLE_BOTTOM', 'L_PENALTY_SPOT']

    # ==========================================
    # 2. åˆå§‹åŒ– (Init)
    # ==========================================
    print(f"ğŸš€ åˆå§‹åŒ– Tactix æ¨¡å—...")

    # A. è§†è§‰æ„ŸçŸ¥
    detector = Detector(model_weights=MODEL_PATH, device='mps', conf_threshold=0.1)
    tracker = Tracker()
    camera_tracker = CameraTracker(initial_keypoints=CALIBRATION_SOURCE) # ğŸ¥ ä¸“é—¨è´Ÿè´£è·Ÿé•œå¤´

    # B. è¯­ä¹‰ä¸å‡ ä½•
    team_classifier = TeamClassifier(device='cpu')
    classifier_trained = False
    
    # æˆ˜æœ¯æ¿ç›®æ ‡ç‚¹æ˜¯å›ºå®šçš„ï¼Œåªéœ€è¦å–ä¸€æ¬¡
    target_points = get_target_points(CALIBRATION_TARGETS)

    # C. æˆ˜æœ¯åˆ†æ
    pass_net = PassNetwork(max_pass_dist=400, ball_owner_dist=60)

    # D. æ¸²æŸ“å™¨
    minimap_renderer = MinimapRenderer(bg_image_path=PITCH_IMAGE_PATH) # ğŸ—ºï¸ ä¸“é—¨è´Ÿè´£ç”»å›¾
    
    # Supervision Annotators
    box_annotator = sv.BoxAnnotator(thickness=2)
    label_annotator = sv.LabelAnnotator(text_scale=0.4)
    ball_annotator = sv.DotAnnotator(color=sv.Color.WHITE, radius=5)

    # è§†é¢‘æµ
    video_info = sv.VideoInfo.from_video_path(SOURCE_VIDEO_PATH)
    frame_generator = sv.get_video_frames_generator(SOURCE_VIDEO_PATH)

    # ==========================================
    # 3. ä¸»å¾ªç¯ (Main Loop)
    # ==========================================
    print(f"â–¶ï¸ å¼€å§‹å¤„ç†...")
    
    with sv.VideoSink(TARGET_VIDEO_PATH, video_info=video_info) as sink:
        for i, frame in tqdm(enumerate(frame_generator), total=video_info.total_frames):
            
            # --- [Step 0] åŠ¨æ€æ ¡å‡† (Camera Update) ---
            # 1. è®© camera_tracker ç®—å‡ºè¿™ä¸€å¸§çš„é‚£ 4 ä¸ªç‚¹è·‘å“ªå»äº†
            current_points = camera_tracker.update(frame)
            
            # 2. ç”¨æ–°ç‚¹é‡æ–°ç”Ÿæˆå˜æ¢çŸ©é˜µ
            view_transformer = ViewTransformer(
                source_points=current_points,
                target_points=target_points
            )

            # --- [Step 1] æ£€æµ‹ä¸è·Ÿè¸ª ---
            frame_data = detector.detect(frame, frame_index=i)
            
            if len(frame_data.players) > 0:
                # æ„é€  tracker éœ€è¦çš„æ•°æ®
                xyxy = np.array([p.rect for p in frame_data.players])
                class_ids = np.array([p.class_id for p in frame_data.players])
                confidences = np.array([0.8] * len(frame_data.players))
                
                detections_sv = sv.Detections(xyxy=xyxy, confidence=confidences, class_id=class_ids)
                tracker.update(detections_sv, frame_data)

            # --- [Step 2] çƒé˜Ÿåˆ†ç±» ---
            valid_players = [p for p in frame_data.players if p.team == TeamID.UNKNOWN]
            if not classifier_trained and len(valid_players) > 5:
                team_classifier.fit(frame, frame_data.players)
                classifier_trained = True
            if classifier_trained:
                team_classifier.predict(frame, frame_data)

            # --- [Step 3] åæ ‡æ˜ å°„ (2D Mapping) ---
            view_transformer.transform_players(frame_data.players)
            if frame_data.ball:
                ball_pos = view_transformer.transform_point(frame_data.ball.center)
                if ball_pos:
                    frame_data.ball.pitch_position = Point(x=ball_pos[0], y=ball_pos[1])

            # --- [Step 4] æˆ˜æœ¯åˆ†æ ---
            pass_lines = pass_net.analyze(frame_data)

            # --- [Step 5] æ¸²æŸ“åˆæˆ (Rendering) ---
            annotated_frame = frame.copy()

            # 5.1 ç”»ä¼ çƒçº¿
            for start, end, opacity in pass_lines:
                overlay = annotated_frame.copy()
                cv2.line(overlay, start, end, (255, 255, 0), 2, cv2.LINE_AA)
                cv2.addWeighted(overlay, opacity, annotated_frame, 1 - opacity, 0, annotated_frame)
                cv2.circle(annotated_frame, end, 4, (255, 255, 0), -1)

            # 5.2 ç”»çƒå‘˜æ¡† (Supervision)
            if len(frame_data.players) > 0:
                # æ˜ å°„ TeamID åˆ°é¢œè‰²ç´¢å¼• (0-4)
                xyxy = np.array([p.rect for p in frame_data.players])
                color_indices = []
                labels = []
                for p in frame_data.players:
                    idx = 4
                    lbl = f"#{p.id}"
                    if p.team == TeamID.A: idx = 0
                    elif p.team == TeamID.B: idx = 1
                    elif p.team == TeamID.REFEREE: idx = 2; lbl = "Ref"
                    elif p.team == TeamID.GOALKEEPER: idx = 3; lbl = "GK"
                    color_indices.append(idx)
                    labels.append(lbl)
                
                det_viz = sv.Detections(xyxy=xyxy, class_id=np.array(color_indices))
                
                # å®šä¹‰é¢œè‰²æ¿
                palette = sv.ColorPalette(colors=[
                    sv.Color(255, 0, 0), sv.Color(0, 0, 255), 
                    sv.Color(255, 255, 0), sv.Color(255, 165, 0), sv.Color(128, 128, 128)
                ])
                box_annotator.color = palette
                label_annotator.color = palette
                
                annotated_frame = box_annotator.annotate(annotated_frame, det_viz)
                annotated_frame = label_annotator.annotate(annotated_frame, det_viz, labels=labels)

            # 5.3 ç”»çƒ
            if frame_data.ball:
                ball_det = sv.Detections(xyxy=np.array([frame_data.ball.rect]), class_id=np.array([0]))
                annotated_frame = ball_annotator.annotate(annotated_frame, ball_det)

            # 5.4 è°ƒè¯•ï¼šç”»å‡ºå…‰æµè·Ÿè¸ªç‚¹ (ç»¿ç‚¹)
            for pt in current_points:
                cv2.circle(annotated_frame, (int(pt[0]), int(pt[1])), 5, (0, 255, 0), -1)

            # 5.5 ç”»ä¸­ç”»ï¼šå°åœ°å›¾
            # è¿™ä¸€æ­¥ç›´æ¥è°ƒç”¨æˆ‘ä»¬å°è£…å¥½çš„ renderer
            minimap_img = minimap_renderer.draw(frame_data)
            
            # ç¼©æ”¾å¹¶è´´å›¾
            target_width = 350
            scale = target_width / minimap_img.shape[1]
            target_height = int(minimap_img.shape[0] * scale)
            minimap_small = cv2.resize(minimap_img, (target_width, target_height))
            
            x_off, y_off = 20, 20
            if y_off + target_height < annotated_frame.shape[0]:
                annotated_frame[y_off:y_off+target_height, x_off:x_off+target_width] = minimap_small
                cv2.rectangle(annotated_frame, (x_off, y_off), (x_off+target_width, y_off+target_height), (255, 255, 255), 2)

            sink.write_frame(annotated_frame)

    print(f"\nâœ… å®Œæˆ! è§†é¢‘ä¿å­˜è‡³: {TARGET_VIDEO_PATH}")

if __name__ == "__main__":
    main()